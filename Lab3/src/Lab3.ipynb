{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "ImagesPath=\"C:\\\\Users\\\\Home\\\\Desktop\\\\Engine\\\\CNN\\\\101_ObjectCategories\\\\\"\n",
    "from os import listdir\n",
    "classes = [f for f in listdir(ImagesPath)]\n",
    "train_volume=0.7\n",
    "size = 128,128\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "for i in range(0,len(classes)):\n",
    "    images=listdir(ImagesPath+classes[i])\n",
    "    for j in range(0,(int)(len(images)*train_volume)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        x_train.append(data)\n",
    "        y_train.append(np.uint8(i))\n",
    "    for j in range((int)(len(images)*train_volume),len(images)):\n",
    "        im=Image.open(ImagesPath+classes[i]+\"\\\\\"+images[j])\n",
    "        im=im.resize(size)\n",
    "        im=im.convert('RGB')\n",
    "        data=img_to_array(im)\n",
    "        data = data/255\n",
    "        x_test.append(data)\n",
    "        y_test.append(np.uint8(i))\n",
    "x_test=np.array(x_test)\n",
    "x_train=np.array(x_train)\n",
    "from keras.utils import to_categorical\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(777)\n",
    "batch_size = 32\n",
    "num_classes = 101\n",
    "epochs = 35\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 127008)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               65028608  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 65,090,565\n",
      "Trainable params: 65,090,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 25s 4ms/step - loss: 5.2770 - acc: 0.0426 - val_loss: 4.7153 - val_acc: 0.0494\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 5.0732 - acc: 0.0536 - val_loss: 4.6493 - val_acc: 0.0494\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 5.0714 - acc: 0.0521 - val_loss: 4.6265 - val_acc: 0.0494\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 5.0196 - acc: 0.0558 - val_loss: 4.5993 - val_acc: 0.0132\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9860 - acc: 0.0577 - val_loss: 4.5731 - val_acc: 0.0905\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9980 - acc: 0.0591 - val_loss: 4.5006 - val_acc: 0.0905\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9774 - acc: 0.0509 - val_loss: 4.5004 - val_acc: 0.0905\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9579 - acc: 0.0591 - val_loss: 4.4861 - val_acc: 0.0905\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9547 - acc: 0.0612 - val_loss: 4.9881 - val_acc: 0.0905\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9571 - acc: 0.0524 - val_loss: 4.5596 - val_acc: 0.0494\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9177 - acc: 0.0589 - val_loss: 4.5570 - val_acc: 0.0905\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9076 - acc: 0.0629 - val_loss: 4.5909 - val_acc: 0.0905\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9208 - acc: 0.0629 - val_loss: 4.5814 - val_acc: 0.0272\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9042 - acc: 0.0636 - val_loss: 4.5189 - val_acc: 0.0905\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9059 - acc: 0.0586 - val_loss: 4.6093 - val_acc: 0.0905\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9266 - acc: 0.0639 - val_loss: 4.5474 - val_acc: 0.0272\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9227 - acc: 0.0616 - val_loss: 4.5740 - val_acc: 0.0102\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9236 - acc: 0.0655 - val_loss: 4.5152 - val_acc: 0.0905\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9132 - acc: 0.0616 - val_loss: 4.5539 - val_acc: 0.0905\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.8999 - acc: 0.0602 - val_loss: 4.5250 - val_acc: 0.0494\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9130 - acc: 0.0568 - val_loss: 4.5364 - val_acc: 0.0905\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9086 - acc: 0.0637 - val_loss: 4.4776 - val_acc: 0.0905\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.8934 - acc: 0.0629 - val_loss: 4.5762 - val_acc: 0.0905\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9136 - acc: 0.0599 - val_loss: 4.9890 - val_acc: 0.0905\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9112 - acc: 0.0596 - val_loss: 5.0924 - val_acc: 0.0905\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.8981 - acc: 0.0609 - val_loss: 4.6218 - val_acc: 0.0905\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.8979 - acc: 0.0612 - val_loss: 4.4721 - val_acc: 0.0905\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9039 - acc: 0.0587 - val_loss: 4.9983 - val_acc: 0.0905\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9122 - acc: 0.0602 - val_loss: 4.8106 - val_acc: 0.0494\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.8988 - acc: 0.0654 - val_loss: 4.5338 - val_acc: 0.0494\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9168 - acc: 0.0607 - val_loss: 4.4499 - val_acc: 0.0905\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9228 - acc: 0.0582 - val_loss: 4.5919 - val_acc: 0.0905\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9107 - acc: 0.0612 - val_loss: 4.9272 - val_acc: 0.0905\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9084 - acc: 0.0604 - val_loss: 4.6666 - val_acc: 0.0905\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.9090 - acc: 0.0637 - val_loss: 4.6231 - val_acc: 0.0905\n"
     ]
    }
   ],
   "source": [
    "model9 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model9.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model9.add(Activation('tanh'))\n",
    "model9.add(Conv2D(32, (3, 3)))\n",
    "model9.add(Activation('tanh'))\n",
    "model9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model9.add(Dropout(0.25))\n",
    "\n",
    "model9.add(Flatten())\n",
    "model9.add(Dense(512))\n",
    "model9.add(Activation('tanh'))\n",
    "model9.add(Dropout(0.5))\n",
    "model9.add(Dense(num_classes))\n",
    "model9.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model9.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model9.summary())\n",
    "\n",
    "model9.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model9, to_file='model9.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 127008)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               65028608  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 65,090,565\n",
      "Trainable params: 65,090,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 4.0977 - acc: 0.1628 - val_loss: 3.2746 - val_acc: 0.3350\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 2.7520 - acc: 0.4185 - val_loss: 2.6700 - val_acc: 0.4229\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 1.3913 - acc: 0.6723 - val_loss: 2.4794 - val_acc: 0.4685\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.4659 - acc: 0.8933 - val_loss: 2.5751 - val_acc: 0.4711\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.1465 - acc: 0.9768 - val_loss: 2.5800 - val_acc: 0.4749\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0757 - acc: 0.9892 - val_loss: 2.5971 - val_acc: 0.4817\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0471 - acc: 0.9934 - val_loss: 2.5824 - val_acc: 0.4836\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0318 - acc: 0.9965 - val_loss: 2.5799 - val_acc: 0.4915\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0186 - acc: 0.9978 - val_loss: 2.6031 - val_acc: 0.4949\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0125 - acc: 0.9992 - val_loss: 2.6411 - val_acc: 0.4972\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0093 - acc: 0.9993 - val_loss: 2.6104 - val_acc: 0.4923\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0069 - acc: 0.9998 - val_loss: 2.6429 - val_acc: 0.4942\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0065 - acc: 0.9997 - val_loss: 2.6488 - val_acc: 0.4919\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0064 - acc: 0.9995 - val_loss: 2.6472 - val_acc: 0.4964\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0047 - acc: 0.9998 - val_loss: 2.6924 - val_acc: 0.4960\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0039 - acc: 0.9997 - val_loss: 2.6819 - val_acc: 0.4953\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0040 - acc: 0.9997 - val_loss: 2.6832 - val_acc: 0.4964\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0040 - acc: 0.9997 - val_loss: 2.6896 - val_acc: 0.4972\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0035 - acc: 0.9997 - val_loss: 2.6785 - val_acc: 0.4960\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0039 - acc: 0.9997 - val_loss: 2.6972 - val_acc: 0.4953\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0036 - acc: 0.9997 - val_loss: 2.7032 - val_acc: 0.4953\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0034 - acc: 0.9997 - val_loss: 2.6958 - val_acc: 0.4957\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0026 - acc: 0.9998 - val_loss: 2.7155 - val_acc: 0.4949\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.7117 - val_acc: 0.4983\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0022 - acc: 0.9997 - val_loss: 2.7087 - val_acc: 0.4983\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7134 - val_acc: 0.4972\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7204 - val_acc: 0.4991\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0018 - acc: 0.9998 - val_loss: 2.7161 - val_acc: 0.4991\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 2.7266 - val_acc: 0.5006\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0020 - acc: 0.9997 - val_loss: 2.7444 - val_acc: 0.4975\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0015 - acc: 0.9998 - val_loss: 2.7348 - val_acc: 0.4979\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.7461 - val_acc: 0.4987\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0016 - acc: 0.9998 - val_loss: 2.7234 - val_acc: 0.4979\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0033 - acc: 0.9997 - val_loss: 2.7260 - val_acc: 0.4979\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 0.0018 - acc: 0.9998 - val_loss: 2.7315 - val_acc: 0.4994\n"
     ]
    }
   ],
   "source": [
    "model10 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model10.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model10.add(Activation('relu'))\n",
    "model10.add(Conv2D(32, (3, 3)))\n",
    "model10.add(Activation('relu'))\n",
    "model10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model10.add(Dropout(0.25))\n",
    "\n",
    "model10.add(Flatten())\n",
    "model10.add(Dense(512))\n",
    "model10.add(Activation('tanh'))\n",
    "model10.add(Dropout(0.5))\n",
    "model10.add(Dense(num_classes))\n",
    "model10.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model10.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model10.summary())\n",
    "\n",
    "model10.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model10, to_file='model10.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               29491712  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 29,609,093\n",
      "Trainable params: 29,609,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 20s 3ms/step - loss: 3.8884 - acc: 0.2041 - val_loss: 3.3999 - val_acc: 0.2848\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 3.2345 - acc: 0.3228 - val_loss: 2.9759 - val_acc: 0.3708\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 2.4890 - acc: 0.4598 - val_loss: 2.4993 - val_acc: 0.4500\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 1.5847 - acc: 0.6170 - val_loss: 2.2232 - val_acc: 0.5062\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.7562 - acc: 0.8068 - val_loss: 2.2650 - val_acc: 0.5153\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.3531 - acc: 0.9162 - val_loss: 2.1908 - val_acc: 0.5232\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.1603 - acc: 0.9685 - val_loss: 2.2059 - val_acc: 0.5270\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0849 - acc: 0.9832 - val_loss: 2.2141 - val_acc: 0.5375\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0582 - acc: 0.9907 - val_loss: 2.1835 - val_acc: 0.5507\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0365 - acc: 0.9949 - val_loss: 2.2460 - val_acc: 0.5477\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0307 - acc: 0.9965 - val_loss: 2.2365 - val_acc: 0.5473\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0221 - acc: 0.9975 - val_loss: 2.2136 - val_acc: 0.5447\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0155 - acc: 0.9990 - val_loss: 2.2202 - val_acc: 0.5549\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0124 - acc: 0.9987 - val_loss: 2.2035 - val_acc: 0.5522\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0115 - acc: 0.9993 - val_loss: 2.2252 - val_acc: 0.5598\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0097 - acc: 0.9992 - val_loss: 2.2433 - val_acc: 0.5594\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0076 - acc: 0.9995 - val_loss: 2.2226 - val_acc: 0.5643\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0075 - acc: 0.9992 - val_loss: 2.2318 - val_acc: 0.5564\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0070 - acc: 0.9997 - val_loss: 2.2075 - val_acc: 0.5628\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0060 - acc: 0.9997 - val_loss: 2.2046 - val_acc: 0.5632\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0057 - acc: 0.9995 - val_loss: 2.2608 - val_acc: 0.5598\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0044 - acc: 0.9998 - val_loss: 2.2637 - val_acc: 0.5579\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0050 - acc: 0.9993 - val_loss: 2.2513 - val_acc: 0.5587\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0043 - acc: 0.9997 - val_loss: 2.2443 - val_acc: 0.5594\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0046 - acc: 0.9997 - val_loss: 2.2386 - val_acc: 0.5609\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0031 - acc: 0.9998 - val_loss: 2.2543 - val_acc: 0.5613\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.2470 - val_acc: 0.5639\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0038 - acc: 0.9998 - val_loss: 2.2533 - val_acc: 0.5628\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0036 - acc: 0.9997 - val_loss: 2.2462 - val_acc: 0.5613\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0033 - acc: 0.9997 - val_loss: 2.2762 - val_acc: 0.5583\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0028 - acc: 0.9998 - val_loss: 2.2757 - val_acc: 0.5651\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0040 - acc: 0.9995 - val_loss: 2.2879 - val_acc: 0.5583\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0043 - acc: 0.9995 - val_loss: 2.2641 - val_acc: 0.5643\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0025 - acc: 0.9998 - val_loss: 2.2688 - val_acc: 0.5666\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 2.2640 - val_acc: 0.5639\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model6.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(Conv2D(32, (3, 3)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Dropout(0.25))\n",
    "\n",
    "model6.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(Conv2D(64, (3, 3)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Dropout(0.25))\n",
    "\n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(512))\n",
    "model6.add(Activation('tanh'))\n",
    "model6.add(Dropout(0.5))\n",
    "model6.add(Dense(num_classes))\n",
    "model6.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model6.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model6.summary())\n",
    "\n",
    "model6.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model6, to_file='model6.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               29491712  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 29,609,093\n",
      "Trainable params: 29,609,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 3.6195 - acc: 0.2600 - val_loss: 3.1007 - val_acc: 0.3229\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 2.4422 - acc: 0.4550 - val_loss: 2.3330 - val_acc: 0.4783\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 1.5059 - acc: 0.6369 - val_loss: 1.9298 - val_acc: 0.5617\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.6505 - acc: 0.8354 - val_loss: 1.8675 - val_acc: 0.5749\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.2280 - acc: 0.9507 - val_loss: 1.8413 - val_acc: 0.5862\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0753 - acc: 0.9897 - val_loss: 1.8775 - val_acc: 0.5911\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0444 - acc: 0.9944 - val_loss: 1.8723 - val_acc: 0.5952\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0234 - acc: 0.9982 - val_loss: 1.8588 - val_acc: 0.5975\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0160 - acc: 0.9990 - val_loss: 1.8195 - val_acc: 0.6084\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0125 - acc: 0.9990 - val_loss: 1.8264 - val_acc: 0.6009\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0082 - acc: 0.9998 - val_loss: 1.8368 - val_acc: 0.6047\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0066 - acc: 0.9997 - val_loss: 1.8497 - val_acc: 0.6051\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0066 - acc: 0.9997 - val_loss: 1.8490 - val_acc: 0.6100\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0054 - acc: 0.9995 - val_loss: 1.8356 - val_acc: 0.6122\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0049 - acc: 0.9998 - val_loss: 1.8350 - val_acc: 0.6100\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0043 - acc: 0.9997 - val_loss: 1.8444 - val_acc: 0.6066\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0044 - acc: 0.9995 - val_loss: 1.8731 - val_acc: 0.6054\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0049 - acc: 0.9997 - val_loss: 1.8578 - val_acc: 0.6058\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.8626 - val_acc: 0.6051\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.8497 - val_acc: 0.6111\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0031 - acc: 0.9998 - val_loss: 1.8516 - val_acc: 0.6092\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0034 - acc: 0.9997 - val_loss: 1.8357 - val_acc: 0.6137\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0025 - acc: 0.9998 - val_loss: 1.8337 - val_acc: 0.6111\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.8471 - val_acc: 0.6126\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0023 - acc: 0.9998 - val_loss: 1.8542 - val_acc: 0.6111\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0021 - acc: 0.9997 - val_loss: 1.8542 - val_acc: 0.6130\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0020 - acc: 0.9998 - val_loss: 1.8398 - val_acc: 0.6164\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0020 - acc: 0.9998 - val_loss: 1.8367 - val_acc: 0.6205\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.8420 - val_acc: 0.6194\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0020 - acc: 0.9997 - val_loss: 1.8525 - val_acc: 0.6171\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 1.8519 - val_acc: 0.6160\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0024 - acc: 0.9997 - val_loss: 1.8466 - val_acc: 0.6141\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0020 - acc: 0.9998 - val_loss: 1.8638 - val_acc: 0.6126\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0035 - acc: 0.9997 - val_loss: 1.8558 - val_acc: 0.6122\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.8608 - val_acc: 0.6137\n"
     ]
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model7.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model7.add(Activation('tanh'))\n",
    "model7.add(Conv2D(32, (3, 3)))\n",
    "model7.add(Activation('tanh'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model7.add(Dropout(0.25))\n",
    "\n",
    "model7.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model7.add(Activation('relu'))\n",
    "model7.add(Conv2D(64, (3, 3)))\n",
    "model7.add(Activation('relu'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model7.add(Dropout(0.25))\n",
    "\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(512))\n",
    "model7.add(Activation('tanh'))\n",
    "model7.add(Dropout(0.5))\n",
    "model7.add(Dense(num_classes))\n",
    "model7.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model7.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model7.summary())\n",
    "\n",
    "model7.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model7, to_file='model7.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               29491712  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 29,609,093\n",
      "Trainable params: 29,609,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 3.6636 - acc: 0.2532 - val_loss: 2.9372 - val_acc: 0.3753\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 2.3373 - acc: 0.4832 - val_loss: 2.5164 - val_acc: 0.4587\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 1.3894 - acc: 0.6573 - val_loss: 2.4487 - val_acc: 0.4723\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.5986 - acc: 0.8487 - val_loss: 2.3029 - val_acc: 0.5108\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.2298 - acc: 0.9519 - val_loss: 2.3628 - val_acc: 0.5149\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.1111 - acc: 0.9804 - val_loss: 2.3162 - val_acc: 0.5236\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0575 - acc: 0.9909 - val_loss: 2.3551 - val_acc: 0.5183\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0337 - acc: 0.9962 - val_loss: 2.3332 - val_acc: 0.5323\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0225 - acc: 0.9985 - val_loss: 2.3265 - val_acc: 0.5262\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0237 - acc: 0.9977 - val_loss: 2.2617 - val_acc: 0.5458\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0168 - acc: 0.9985 - val_loss: 2.2681 - val_acc: 0.5439\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0117 - acc: 0.9993 - val_loss: 2.2900 - val_acc: 0.5390\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0094 - acc: 0.9997 - val_loss: 2.2706 - val_acc: 0.5390\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0097 - acc: 0.9995 - val_loss: 2.2640 - val_acc: 0.5470\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.2728 - val_acc: 0.5458\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0055 - acc: 0.9998 - val_loss: 2.2753 - val_acc: 0.5522\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0058 - acc: 0.9993 - val_loss: 2.2779 - val_acc: 0.5436\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0047 - acc: 0.9998 - val_loss: 2.2678 - val_acc: 0.5481\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0049 - acc: 0.9997 - val_loss: 2.2949 - val_acc: 0.5409\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0053 - acc: 0.9997 - val_loss: 2.2688 - val_acc: 0.5549\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0039 - acc: 0.9998 - val_loss: 2.2671 - val_acc: 0.5534\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0042 - acc: 0.9998 - val_loss: 2.2908 - val_acc: 0.5481\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0047 - acc: 0.9995 - val_loss: 2.2757 - val_acc: 0.5579\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0035 - acc: 0.9997 - val_loss: 2.2628 - val_acc: 0.5500\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0033 - acc: 0.9997 - val_loss: 2.2590 - val_acc: 0.5571\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0032 - acc: 0.9997 - val_loss: 2.2637 - val_acc: 0.5553\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0035 - acc: 0.9998 - val_loss: 2.2718 - val_acc: 0.5500\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.2650 - val_acc: 0.5534\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 2.2827 - val_acc: 0.5526\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0029 - acc: 0.9995 - val_loss: 2.2715 - val_acc: 0.5507\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0026 - acc: 0.9998 - val_loss: 2.2716 - val_acc: 0.5553\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0022 - acc: 0.9998 - val_loss: 2.2627 - val_acc: 0.5526\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 2.2585 - val_acc: 0.5568\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0019 - acc: 0.9998 - val_loss: 2.2604 - val_acc: 0.5556\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 19s 3ms/step - loss: 0.0022 - acc: 0.9998 - val_loss: 2.2749 - val_acc: 0.5594\n"
     ]
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model8.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model8.add(Activation('relu'))\n",
    "model8.add(Conv2D(32, (3, 3)))\n",
    "model8.add(Activation('relu'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(0.25))\n",
    "\n",
    "model8.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model8.add(Activation('linear'))\n",
    "model8.add(Conv2D(64, (3, 3)))\n",
    "model8.add(Activation('linear'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(0.25))\n",
    "\n",
    "model8.add(Flatten())\n",
    "model8.add(Dense(512))\n",
    "model8.add(Activation('tanh'))\n",
    "model8.add(Dropout(0.5))\n",
    "model8.add(Dense(num_classes))\n",
    "model8.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model8.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model8.summary())\n",
    "\n",
    "model8.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model8, to_file='model8.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 11,808,133\n",
      "Trainable params: 11,808,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 3.7498 - acc: 0.2250 - val_loss: 2.9580 - val_acc: 0.3817\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 2.8920 - acc: 0.3868 - val_loss: 3.2520 - val_acc: 0.3304\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 2.2275 - acc: 0.4935 - val_loss: 2.4089 - val_acc: 0.4798\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 1.6753 - acc: 0.6017 - val_loss: 2.1182 - val_acc: 0.5247\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 1.2015 - acc: 0.6917 - val_loss: 2.1184 - val_acc: 0.5356\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.8336 - acc: 0.7818 - val_loss: 2.0527 - val_acc: 0.5470\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.5839 - acc: 0.8336 - val_loss: 1.9149 - val_acc: 0.5851\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.3735 - acc: 0.8978 - val_loss: 1.9870 - val_acc: 0.5843\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.2523 - acc: 0.9308 - val_loss: 1.9932 - val_acc: 0.5817\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.1695 - acc: 0.9588 - val_loss: 1.9611 - val_acc: 0.5934\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.1235 - acc: 0.9711 - val_loss: 1.9753 - val_acc: 0.5851\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0848 - acc: 0.9827 - val_loss: 1.9533 - val_acc: 0.6020\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0705 - acc: 0.9864 - val_loss: 1.9759 - val_acc: 0.5960\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0532 - acc: 0.9910 - val_loss: 1.9796 - val_acc: 0.6028\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0436 - acc: 0.9912 - val_loss: 1.9591 - val_acc: 0.6058\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0349 - acc: 0.9944 - val_loss: 1.9476 - val_acc: 0.6175\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0290 - acc: 0.9967 - val_loss: 1.9781 - val_acc: 0.6092\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0275 - acc: 0.9960 - val_loss: 1.9910 - val_acc: 0.6043\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0211 - acc: 0.9980 - val_loss: 1.9684 - val_acc: 0.6111\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0160 - acc: 0.9990 - val_loss: 1.9551 - val_acc: 0.6107\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0181 - acc: 0.9977 - val_loss: 2.0052 - val_acc: 0.6081\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0140 - acc: 0.9987 - val_loss: 1.9591 - val_acc: 0.6179\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0145 - acc: 0.9983 - val_loss: 1.9602 - val_acc: 0.6164\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0122 - acc: 0.9988 - val_loss: 1.9750 - val_acc: 0.6171\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0107 - acc: 0.9992 - val_loss: 1.9715 - val_acc: 0.6194\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0098 - acc: 0.9997 - val_loss: 2.0054 - val_acc: 0.6190\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0087 - acc: 0.9993 - val_loss: 1.9914 - val_acc: 0.6167\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0095 - acc: 0.9988 - val_loss: 2.0695 - val_acc: 0.6096\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0126 - acc: 0.9983 - val_loss: 1.9966 - val_acc: 0.6183\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0092 - acc: 0.9997 - val_loss: 1.9852 - val_acc: 0.6198\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0072 - acc: 0.9995 - val_loss: 1.9834 - val_acc: 0.6194\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0082 - acc: 0.9988 - val_loss: 1.9981 - val_acc: 0.6167\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0075 - acc: 0.9993 - val_loss: 2.0077 - val_acc: 0.6186\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0073 - acc: 0.9993 - val_loss: 2.0092 - val_acc: 0.6145\n",
      "Epoch 35/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0075 - acc: 0.9995 - val_loss: 1.9845 - val_acc: 0.6228\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model1.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(32, (3, 3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(64, (3, 3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model1.add(Activation('tanh'))\n",
    "model1.add(Conv2D(128, (5, 5)))\n",
    "model1.add(Activation('tanh'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(512))\n",
    "model1.add(Activation('tanh'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(num_classes))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model1.summary())\n",
    "\n",
    "model1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model1, to_file='model1.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 11,808,133\n",
      "Trainable params: 11,808,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.4754 - acc: 0.0818 - val_loss: 4.2477 - val_acc: 0.0905\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2549 - acc: 0.0889 - val_loss: 4.3906 - val_acc: 0.0905\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2509 - acc: 0.0858 - val_loss: 4.2383 - val_acc: 0.0905\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2476 - acc: 0.0931 - val_loss: 4.2364 - val_acc: 0.0905\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2408 - acc: 0.0913 - val_loss: 4.2232 - val_acc: 0.0905\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2397 - acc: 0.0889 - val_loss: 4.2279 - val_acc: 0.0905\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2366 - acc: 0.0903 - val_loss: 4.2352 - val_acc: 0.0905\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2274 - acc: 0.0933 - val_loss: 4.2260 - val_acc: 0.0905\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2269 - acc: 0.0931 - val_loss: 4.2293 - val_acc: 0.0905\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2219 - acc: 0.0933 - val_loss: 4.2117 - val_acc: 0.0905\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2237 - acc: 0.0893 - val_loss: 4.2284 - val_acc: 0.0905\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2271 - acc: 0.0870 - val_loss: 4.2166 - val_acc: 0.0905\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2245 - acc: 0.0933 - val_loss: 4.2286 - val_acc: 0.0905\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2233 - acc: 0.0976 - val_loss: 4.2167 - val_acc: 0.0905\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2197 - acc: 0.0977 - val_loss: 4.2144 - val_acc: 0.0905\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2267 - acc: 0.0946 - val_loss: 4.2285 - val_acc: 0.0905\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2276 - acc: 0.0913 - val_loss: 4.2183 - val_acc: 0.0905\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2216 - acc: 0.0971 - val_loss: 4.2278 - val_acc: 0.0905\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2216 - acc: 0.0919 - val_loss: 4.2401 - val_acc: 0.0905\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2254 - acc: 0.0899 - val_loss: 4.2133 - val_acc: 0.0905\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2211 - acc: 0.0931 - val_loss: 4.2162 - val_acc: 0.0905\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2247 - acc: 0.0894 - val_loss: 4.2295 - val_acc: 0.0905\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2229 - acc: 0.0954 - val_loss: 4.2390 - val_acc: 0.0905\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2221 - acc: 0.0934 - val_loss: 4.2243 - val_acc: 0.0905\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2233 - acc: 0.0918 - val_loss: 4.2268 - val_acc: 0.0905\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2224 - acc: 0.0936 - val_loss: 4.2179 - val_acc: 0.0905\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2249 - acc: 0.0908 - val_loss: 4.2166 - val_acc: 0.0905\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2197 - acc: 0.0909 - val_loss: 4.2178 - val_acc: 0.0905\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2236 - acc: 0.0951 - val_loss: 4.2163 - val_acc: 0.0905\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2198 - acc: 0.0904 - val_loss: 4.2139 - val_acc: 0.0905\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2181 - acc: 0.0951 - val_loss: 4.2219 - val_acc: 0.0905\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2214 - acc: 0.0918 - val_loss: 4.2149 - val_acc: 0.0905\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2168 - acc: 0.0908 - val_loss: 4.2198 - val_acc: 0.0905\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2212 - acc: 0.0913 - val_loss: 4.2099 - val_acc: 0.0905\n",
      "Epoch 35/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6026/6026 [==============================] - 21s 3ms/step - loss: 4.2141 - acc: 0.0908 - val_loss: 4.2224 - val_acc: 0.0905\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model2.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(64, (3, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model2.add(Activation('tanh'))\n",
    "model2.add(Conv2D(128, (5, 5)))\n",
    "model2.add(Activation('tanh'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(512))\n",
    "model2.add(Activation('tanh'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(num_classes))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "model2.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model2, to_file='model2.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 11,808,133\n",
      "Trainable params: 11,808,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 5.2230 - acc: 0.0521 - val_loss: 4.5456 - val_acc: 0.0905\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 5.1183 - acc: 0.0568 - val_loss: 4.6366 - val_acc: 0.0905\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 5.0743 - acc: 0.0539 - val_loss: 4.9895 - val_acc: 0.0905\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 5.0228 - acc: 0.0606 - val_loss: 4.5541 - val_acc: 0.0272\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9999 - acc: 0.0586 - val_loss: 4.6549 - val_acc: 0.0494\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9930 - acc: 0.0574 - val_loss: 4.6534 - val_acc: 0.0494\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9648 - acc: 0.0596 - val_loss: 4.6444 - val_acc: 0.0905\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9631 - acc: 0.0597 - val_loss: 4.5547 - val_acc: 0.0905\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9458 - acc: 0.0564 - val_loss: 4.4836 - val_acc: 0.0494\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9418 - acc: 0.0604 - val_loss: 4.4267 - val_acc: 0.0905\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9055 - acc: 0.0621 - val_loss: 4.4709 - val_acc: 0.0905\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9316 - acc: 0.0601 - val_loss: 4.5378 - val_acc: 0.0905\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9313 - acc: 0.0611 - val_loss: 4.4996 - val_acc: 0.0905\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9237 - acc: 0.0579 - val_loss: 4.7157 - val_acc: 0.0905\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9173 - acc: 0.0601 - val_loss: 4.5632 - val_acc: 0.0905\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9194 - acc: 0.0601 - val_loss: 4.5222 - val_acc: 0.0905 - loss: \n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9217 - acc: 0.0631 - val_loss: 5.1807 - val_acc: 0.0905\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9049 - acc: 0.0569 - val_loss: 4.8168 - val_acc: 0.0494\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9209 - acc: 0.0621 - val_loss: 4.9502 - val_acc: 0.0905\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9171 - acc: 0.0592 - val_loss: 4.4993 - val_acc: 0.0494\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9273 - acc: 0.0581 - val_loss: 4.6672 - val_acc: 0.0494ss: 4.9279 - acc: 0.058\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9286 - acc: 0.0574 - val_loss: 4.5710 - val_acc: 0.0905\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9252 - acc: 0.0627 - val_loss: 4.5743 - val_acc: 0.0905\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.8976 - acc: 0.0604 - val_loss: 4.6529 - val_acc: 0.0905\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9369 - acc: 0.0606 - val_loss: 4.7262 - val_acc: 0.0905 loss: 4.9333 \n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.8794 - acc: 0.0637 - val_loss: 4.5369 - val_acc: 0.0494\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9266 - acc: 0.0597 - val_loss: 4.5002 - val_acc: 0.0905\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9138 - acc: 0.0601 - val_loss: 4.4215 - val_acc: 0.0905\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9278 - acc: 0.0571 - val_loss: 4.7288 - val_acc: 0.0272\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9432 - acc: 0.0612 - val_loss: 4.5846 - val_acc: 0.0226\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9057 - acc: 0.0664 - val_loss: 4.7188 - val_acc: 0.0494\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9198 - acc: 0.0582 - val_loss: 4.6510 - val_acc: 0.0905\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.8907 - acc: 0.0626 - val_loss: 4.5152 - val_acc: 0.0905\n",
      "Epoch 34/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.9191 - acc: 0.0626 - val_loss: 4.5252 - val_acc: 0.0494\n",
      "Epoch 35/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 4.8964 - acc: 0.0609 - val_loss: 4.5677 - val_acc: 0.0905\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model3.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Conv2D(32, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.25))\n",
    "\n",
    "model3.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Conv2D(64, (3, 3)))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.25))\n",
    "\n",
    "model3.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Conv2D(128, (5, 5)))\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.25))\n",
    "\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(512))\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(num_classes))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model3.summary())\n",
    "\n",
    "model3.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model3, to_file='model3.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 11,808,133\n",
      "Trainable params: 11,808,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.0424 - acc: 0.1623 - val_loss: 3.3694 - val_acc: 0.3018\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 3.0364 - acc: 0.3662 - val_loss: 2.6979 - val_acc: 0.4247\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 2.2924 - acc: 0.4849 - val_loss: 2.4111 - val_acc: 0.4693\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 1.7418 - acc: 0.5838 - val_loss: 2.2784 - val_acc: 0.4896\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 1.2641 - acc: 0.6761 - val_loss: 2.1096 - val_acc: 0.5270\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.8596 - acc: 0.7688 - val_loss: 2.1413 - val_acc: 0.5273\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.6026 - acc: 0.8306 - val_loss: 2.1024 - val_acc: 0.5462\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.4152 - acc: 0.8857 - val_loss: 2.1415 - val_acc: 0.5507\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.2943 - acc: 0.9205 - val_loss: 2.2373 - val_acc: 0.5436\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.2100 - acc: 0.9476 - val_loss: 2.2006 - val_acc: 0.5602\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.1446 - acc: 0.9656 - val_loss: 2.2774 - val_acc: 0.5511\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.1288 - acc: 0.9671 - val_loss: 2.2412 - val_acc: 0.5583\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0923 - acc: 0.9796 - val_loss: 2.3045 - val_acc: 0.5575\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0728 - acc: 0.9861 - val_loss: 2.2438 - val_acc: 0.5651\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0706 - acc: 0.9831 - val_loss: 2.2384 - val_acc: 0.5636\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0595 - acc: 0.9876 - val_loss: 2.2339 - val_acc: 0.5662\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0444 - acc: 0.9914 - val_loss: 2.2679 - val_acc: 0.5730\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0356 - acc: 0.9937 - val_loss: 2.2988 - val_acc: 0.5639\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0368 - acc: 0.9929 - val_loss: 2.2629 - val_acc: 0.5692\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0296 - acc: 0.9944 - val_loss: 2.3039 - val_acc: 0.5707\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0295 - acc: 0.9935 - val_loss: 2.3130 - val_acc: 0.5734\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0243 - acc: 0.9965 - val_loss: 2.2695 - val_acc: 0.5756\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0259 - acc: 0.9954 - val_loss: 2.3206 - val_acc: 0.5734\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0219 - acc: 0.9955 - val_loss: 2.3242 - val_acc: 0.5734\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0220 - acc: 0.9959 - val_loss: 2.3718 - val_acc: 0.5692\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0163 - acc: 0.9972 - val_loss: 2.3295 - val_acc: 0.5722\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0139 - acc: 0.9978 - val_loss: 2.3208 - val_acc: 0.5775\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0143 - acc: 0.9975 - val_loss: 2.3446 - val_acc: 0.5707\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0139 - acc: 0.9980 - val_loss: 2.3663 - val_acc: 0.5737\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0126 - acc: 0.9978 - val_loss: 2.3371 - val_acc: 0.5756\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0119 - acc: 0.9992 - val_loss: 2.3332 - val_acc: 0.5771\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0114 - acc: 0.9983 - val_loss: 2.3492 - val_acc: 0.5820\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0114 - acc: 0.9987 - val_loss: 2.3340 - val_acc: 0.5851\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0123 - acc: 0.9978 - val_loss: 2.4147 - val_acc: 0.5737\n",
      "Epoch 35/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6026/6026 [==============================] - 21s 4ms/step - loss: 0.0119 - acc: 0.9988 - val_loss: 2.3274 - val_acc: 0.5813\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model4.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Conv2D(32, (3, 3)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "model4.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Conv2D(64, (3, 3)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "model4.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Conv2D(128, (5, 5)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(512))\n",
    "model4.add(Activation('tanh'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(num_classes))\n",
    "model4.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model4.summary())\n",
    "\n",
    "model4.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model4, to_file='model4.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 126, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               11076096  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 11,808,133\n",
      "Trainable params: 11,808,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6026 samples, validate on 2651 samples\n",
      "Epoch 1/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 5.1848 - acc: 0.0516 - val_loss: 4.5174 - val_acc: 0.0905\n",
      "Epoch 2/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 5.1115 - acc: 0.0511 - val_loss: 4.5551 - val_acc: 0.0494\n",
      "Epoch 3/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 5.0584 - acc: 0.0568 - val_loss: 4.6386 - val_acc: 0.0905\n",
      "Epoch 4/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 5.0328 - acc: 0.0523 - val_loss: 4.5411 - val_acc: 0.0905\n",
      "Epoch 5/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9874 - acc: 0.0579 - val_loss: 4.6066 - val_acc: 0.0905\n",
      "Epoch 6/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9622 - acc: 0.0636 - val_loss: 4.5317 - val_acc: 0.0905\n",
      "Epoch 7/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9978 - acc: 0.0579 - val_loss: 4.6136 - val_acc: 0.0494\n",
      "Epoch 8/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9833 - acc: 0.0577 - val_loss: 4.6083 - val_acc: 0.0494\n",
      "Epoch 9/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9381 - acc: 0.0534 - val_loss: 4.6652 - val_acc: 0.0905\n",
      "Epoch 10/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9327 - acc: 0.0619 - val_loss: 4.4904 - val_acc: 0.0494\n",
      "Epoch 11/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9119 - acc: 0.0581 - val_loss: 4.5632 - val_acc: 0.0905\n",
      "Epoch 12/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9422 - acc: 0.0619 - val_loss: 4.5013 - val_acc: 0.0905\n",
      "Epoch 13/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9260 - acc: 0.0566 - val_loss: 4.7197 - val_acc: 0.0905\n",
      "Epoch 14/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9293 - acc: 0.0591 - val_loss: 4.6153 - val_acc: 0.0494\n",
      "Epoch 15/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9168 - acc: 0.0573 - val_loss: 4.8089 - val_acc: 0.0905\n",
      "Epoch 16/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9064 - acc: 0.0619 - val_loss: 4.8718 - val_acc: 0.0905\n",
      "Epoch 17/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9136 - acc: 0.0611 - val_loss: 4.6143 - val_acc: 0.0494\n",
      "Epoch 18/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9294 - acc: 0.0586 - val_loss: 4.7088 - val_acc: 0.0072\n",
      "Epoch 19/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.8975 - acc: 0.0647 - val_loss: 4.5037 - val_acc: 0.0905\n",
      "Epoch 20/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.8981 - acc: 0.0569 - val_loss: 4.6158 - val_acc: 0.0494\n",
      "Epoch 21/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9049 - acc: 0.0636 - val_loss: 4.5397 - val_acc: 0.0226\n",
      "Epoch 22/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9047 - acc: 0.0637 - val_loss: 4.5568 - val_acc: 0.0494\n",
      "Epoch 23/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9100 - acc: 0.0561 - val_loss: 4.8029 - val_acc: 0.0905\n",
      "Epoch 24/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.8824 - acc: 0.0577 - val_loss: 4.6363 - val_acc: 0.0905\n",
      "Epoch 25/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.8942 - acc: 0.0641 - val_loss: 4.5231 - val_acc: 0.0494\n",
      "Epoch 26/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9005 - acc: 0.0621 - val_loss: 4.5272 - val_acc: 0.0147\n",
      "Epoch 27/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.8927 - acc: 0.0664 - val_loss: 4.5550 - val_acc: 0.0905\n",
      "Epoch 28/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9009 - acc: 0.0626 - val_loss: 4.5569 - val_acc: 0.0905\n",
      "Epoch 29/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9232 - acc: 0.0568 - val_loss: 4.5652 - val_acc: 0.0905\n",
      "Epoch 30/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9200 - acc: 0.0589 - val_loss: 4.6071 - val_acc: 0.0083\n",
      "Epoch 31/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9002 - acc: 0.0569 - val_loss: 4.5271 - val_acc: 0.0272\n",
      "Epoch 32/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9177 - acc: 0.0601 - val_loss: 4.9019 - val_acc: 0.0494\n",
      "Epoch 33/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.8980 - acc: 0.0616 - val_loss: 4.4755 - val_acc: 0.0905\n",
      "Epoch 34/35\n",
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.9072 - acc: 0.0642 - val_loss: 4.5744 - val_acc: 0.0905\n",
      "Epoch 35/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6026/6026 [==============================] - 22s 4ms/step - loss: 4.8860 - acc: 0.0612 - val_loss: 4.5226 - val_acc: 0.0905\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model5.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model5.add(Activation('tanh'))\n",
    "model5.add(Conv2D(32, (3, 3)))\n",
    "model5.add(Activation('tanh'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.25))\n",
    "\n",
    "model5.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model5.add(Activation('tanh'))\n",
    "model5.add(Conv2D(64, (3, 3)))\n",
    "model5.add(Activation('tanh'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.25))\n",
    "\n",
    "model5.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model5.add(Activation('tanh'))\n",
    "model5.add(Conv2D(128, (5, 5)))\n",
    "model5.add(Activation('tanh'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.25))\n",
    "\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(512))\n",
    "model5.add(Activation('tanh'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(num_classes))\n",
    "model5.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Let's train the model using RMSprop\n",
    "model5.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model5.summary())\n",
    "\n",
    "model5.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model5, to_file='model5.png', show_shapes=True, show_layer_names=False, rankdir='LR')\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
